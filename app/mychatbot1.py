# -*- coding: utf-8 -*-
"""MyChatbot1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fZHi3MUoCoH1I92yvm7fqNj81WrfQa6v
"""



import os
import openai as OpenAI
from langchain.chains import SequentialChain, LLMChain
from langchain_community.chat_models import ChatOpenAI as ChatOpenAI
import whisper
# Import Prompt objects
from langchain.prompts import PromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate
# Import memory
from langchain.memory import ConversationKGMemory, ConversationBufferMemory
from langchain.output_parsers import CommaSeparatedListOutputParser
from typing import Dict, Any

# API-KEY
OPENAI_API_KEY = ''

# Set the API key in the system environment variables
os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY

# Load Whisper model
model = whisper.load_model("base")

def audio_to_text(audio_file):
    result = model.transcribe(audio_file)
    return result["text"]


def text_to_audio(text):
    result = OpenAI.audio.speech.create(
        model="tts-1",
        voice="nova",
        input=text
        )
    return result

# Create ChatOpenAI object with API_KEY
chatgpt = ChatOpenAI(openai_api_key=OPENAI_API_KEY)
memory = ConversationKGMemory(llm=chatgpt, output_key="instrucciones")

# Initialize comma separated parser
output_parser = CommaSeparatedListOutputParser()
# Get instructions from parser in String format
format_instructions = output_parser.get_format_instructions()

### Prompts

## system + human prompt

# Main template
template_sistema = """Eres un chef de cocina experto que da consejos breves sobre recetas de cocina con el tiempo y los ingredientes que se tienen en casa."""

# Create basic prompt with the main template
prompt_sistema = PromptTemplate(template=template_sistema)

# Create SystemMessagePromptTemplate
template_sistema = SystemMessagePromptTemplate(prompt=prompt_sistema)

# Now the same for the human with an empty template
prompt_humano = PromptTemplate(template="{pregunta}", input_variables=["pregunta"])
template_humano = HumanMessagePromptTemplate(prompt=prompt_humano)

# Chat template created from system and human prompts
chat_prompt = ChatPromptTemplate.from_messages([template_sistema, template_humano])

# Create LLMChain from chat_prompt
chat_chain = LLMChain(llm=chatgpt, prompt=chat_prompt, output_key="platillo")

## Output parser prompt

# Initialize comma separated parser
output_parser = CommaSeparatedListOutputParser()

# Get instructions from parser in String format
format_instructions = output_parser.get_format_instructions()

# Template with input variables {platillo} & {parsear}
template_ingredientes_parser = """¿Cuáles son los ingredientes y su porción para preparar: {platillo}\n{parsear}?"""

# Prompt for generating ingredients list
prompt_ingredientes_parser = PromptTemplate(template=template_ingredientes_parser, input_variables=["platillo"], partial_variables={"parsear":format_instructions + '\n Add the "platillo" name to the list'})

# Create LLMChain from prompt_ingredientes_parser
ingredientes_chain = LLMChain(llm=chatgpt, prompt=prompt_ingredientes_parser, output_key="ingredientes")

## Instructions prompt

# Template with input variables {platillo} & {parsear}
template_instrucciones_parser = """¿Cuáles son los pasos para preparar: {platillo} con los siguientes ingredientes: {ingredientes}?"""

# Prompt for generating instruccions list
prompt_instrucciones_parser = PromptTemplate(template=template_instrucciones_parser, input_variables=["platillo", "ingredientes"])

# Create LLMChain from prompt_instrucciones_parser
instrucciones_chain = LLMChain(llm=chatgpt, prompt=prompt_instrucciones_parser, output_key="instrucciones")

class ChatBot(SequentialChain):
    def __init__(self):
        super().__init__(
            chains=[chat_chain, ingredientes_chain, instrucciones_chain],
            input_variables=["pregunta"],
            output_variables=["platillo", "ingredientes", "instrucciones"],
            verbose=True,
            memory=memory,
        )

    def format_response(self, response):
        # Parse the platillo to extract the dish name
        platillo_name = response["platillo"].split('\n')[0].strip()

        # Ensure ingredientes is a list
        ingredientes_list = response["ingredientes"].split(", ")

        # Ensure instrucciones is a list of steps
        instrucciones_list = response["instrucciones"].split("\n")

        # Create the formatted JSON response
        formatted_response = {
            "pregunta": response["pregunta"],
            "Platillo": platillo_name,
            "ingredientes": ingredientes_list,
            "instrucciones": instrucciones_list
        }

        return formatted_response

    def process_audio(self, audio_path):
        # Transcribe audio to text
        pregunta = audio_to_text(audio_path)

        # Generate the response using the transcribed text
        response = self({"pregunta": pregunta})

        return response

    def instrucciones_to_audio(self, instrucciones, output_path):
        # Join instructions into a single string
        instrucciones_text = " ".join(instrucciones)
        # Convert text to audio and save to file
        return text_to_audio(instrucciones_text).stream_to_file(output_path)

